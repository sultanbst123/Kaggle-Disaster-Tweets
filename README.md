# Kaggle-Disaster-Tweets

Mengunakan DistilBert & Bert-base dan menambahkan bi-lstm + Fc, untuk memprediksi Tweet bencana dan yang tidak, 

### DistilBert: 
- Optimizer = AdamW 
- Learning Rate = 3e-5
- Weight decay = 1e-4

### Bert Base: 
- Optimizer = AdaBelief
- Learning Rate = 3e-5
- Weight decay = 1e-4

## Dataset & Informasi
https://www.kaggle.com/c/nlp-getting-started/overview
